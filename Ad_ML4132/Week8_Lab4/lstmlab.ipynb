{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8983cf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-10T02:56:28.642859Z",
     "iopub.status.busy": "2025-11-10T02:56:28.642579Z",
     "iopub.status.idle": "2025-11-10T02:56:34.658791Z",
     "shell.execute_reply": "2025-11-10T02:56:34.657952Z"
    },
    "papermill": {
     "duration": 6.020813,
     "end_time": "2025-11-10T02:56:34.659998",
     "exception": false,
     "start_time": "2025-11-10T02:56:28.639185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "成功找到数据文件: /kaggle/input/short-jokes/shortjokes.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "DATA_PATH = '/kaggle/input/short-jokes/shortjokes.csv'\n",
    "\n",
    "if os.path.exists(DATA_PATH):\n",
    "    print(f\"成功找到数据文件: {DATA_PATH}\")\n",
    "else:\n",
    "    print(f\"错误：文件不存在 {DATA_PATH}\")\n",
    "    print(\"请检查 /kaggle/input/short-jokes/ 目录下的文件:\")\n",
    "    print(os.listdir('/kaggle/input/short-jokes/'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4600255c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T02:56:34.664923Z",
     "iopub.status.busy": "2025-11-10T02:56:34.664578Z",
     "iopub.status.idle": "2025-11-10T02:56:36.835982Z",
     "shell.execute_reply": "2025-11-10T02:56:36.835106Z"
    },
    "papermill": {
     "duration": 2.175135,
     "end_time": "2025-11-10T02:56:36.837239",
     "exception": false,
     "start_time": "2025-11-10T02:56:34.662104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 创建数据集 (修正后) ---\n",
      "成功找到笑话列: 'Joke'\n",
      "词汇过滤前: 191284, 过滤后(出现>=2次): 77741\n",
      "总词数: 4071141\n",
      "最终词汇表大小 (包含<unk>): 77742\n",
      "可训练样本数: 4071137\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.listOfWords = self.loadWords()\n",
    "        self.listOfUniqueWords = self.obtainUniqueWords()\n",
    "        self.id2word = {i: w for i, w in enumerate(self.listOfUniqueWords)}\n",
    "        self.word2id = {w: i for i, w in enumerate(self.listOfUniqueWords)}\n",
    "\n",
    "        unk_id = self.word2id['<unk>']\n",
    "        self.listOfIds = [self.word2id.get(w, unk_id) for w in self.listOfWords]\n",
    "\n",
    "    def loadWords(self):\n",
    "        try:\n",
    "            csvData = pd.read_csv(DATA_PATH)\n",
    "            joke_column = None\n",
    "            for col in csvData.columns:\n",
    "                if 'joke' in col.lower():\n",
    "                    joke_column = col\n",
    "                    break\n",
    "            \n",
    "            if joke_column is None:\n",
    "                joke_column = csvData.columns[0]\n",
    "                print(f\"警告：未找到包含'joke'的列，默认使用第一列: '{joke_column}'\")\n",
    "            else:\n",
    "                print(f\"成功找到笑话列: '{joke_column}'\")\n",
    "\n",
    "            text = csvData[joke_column].str.cat(sep=' ').lower()\n",
    "            return text.split(' ')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"加载数据时出错: {e}\")\n",
    "            return []\n",
    "\n",
    "    def obtainUniqueWords(self):\n",
    "        wordCounts = Counter(self.listOfWords)\n",
    "        min_count = 2\n",
    "        filtered_words = {word: count for word, count in wordCounts.items() if count >= min_count}\n",
    "        print(f\"词汇过滤前: {len(wordCounts)}, 过滤后(出现>=2次): {len(filtered_words)}\")\n",
    "        sorted_words = sorted(filtered_words, key=filtered_words.get, reverse=True)\n",
    "\n",
    "        return ['<unk>'] + sorted_words\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.listOfIds) - 4\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.listOfIds[index:index+4]),\n",
    "            torch.tensor(self.listOfIds[index+1:index+4+1])\n",
    "        )\n",
    "    \n",
    "print(\"\\n--- 创建数据集 (修正后) ---\")\n",
    "dataset = MyDataset()\n",
    "VOCAB_SIZE = len(dataset.listOfUniqueWords)\n",
    "print(f\"总词数: {len(dataset.listOfWords)}\")\n",
    "print(f\"最终词汇表大小 (包含<unk>): {VOCAB_SIZE}\")\n",
    "print(f\"可训练样本数: {len(dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e715a6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T02:56:36.842088Z",
     "iopub.status.busy": "2025-11-10T02:56:36.841560Z",
     "iopub.status.idle": "2025-11-10T02:56:36.847489Z",
     "shell.execute_reply": "2025-11-10T02:56:36.846877Z"
    },
    "papermill": {
     "duration": 0.009485,
     "end_time": "2025-11-10T02:56:36.848582",
     "exception": false,
     "start_time": "2025-11-10T02:56:36.839097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型类定义完成！\n"
     ]
    }
   ],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        embedded = self.embedding(x)  \n",
    "\n",
    "        lstm_out, hidden = self.lstm(embedded, hidden)  \n",
    "\n",
    "        output = self.fc(lstm_out) \n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        h0 = torch.zeros(1, batch_size, self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(1, batch_size, self.hidden_dim).to(device)\n",
    "        return (h0, c0)\n",
    "\n",
    "print(\"模型类定义完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf0d4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T02:56:36.853000Z",
     "iopub.status.busy": "2025-11-10T02:56:36.852751Z",
     "iopub.status.idle": "2025-11-10T05:23:53.890532Z",
     "shell.execute_reply": "2025-11-10T05:23:53.889725Z"
    },
    "papermill": {
     "duration": 8837.041694,
     "end_time": "2025-11-10T05:23:53.891968",
     "exception": false,
     "start_time": "2025-11-10T02:56:36.850274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "模型参数数量: 30,325,934\n",
      "\n",
      "--- 开始训练 ---\n",
      "Epoch 1/10, 平均损失: 5.5893\n",
      "Epoch 2/10, 平均损失: 5.0876\n",
      "Epoch 3/10, 平均损失: 4.9231\n",
      "Epoch 4/10, 平均损失: 4.8245\n",
      "Epoch 5/10, 平均损失: 4.7674\n",
      "Epoch 6/10, 平均损失: 4.7304\n",
      "Epoch 7/10, 平均损失: 4.6956\n",
      "Epoch 8/10, 平均损失: 4.6733\n",
      "Epoch 9/10, 平均损失: 4.6648\n",
      "Epoch 10/10, 平均损失: 4.6544\n",
      "--- 训练完成 ---\n",
      "模型已保存到: lstm_joke_generator.pth\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64      \n",
    "EMBED_DIM = 128      \n",
    "HIDDEN_DIM = 256     \n",
    "EPOCHS = 10          \n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = LSTMModel(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"\\n模型参数数量: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "print(\"\\n--- 开始训练 ---\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs, _ = model(inputs)\n",
    " \n",
    "        loss = criterion(outputs.view(-1, VOCAB_SIZE), targets.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, 平均损失: {avg_loss:.4f}')\n",
    "\n",
    "print(\"--- 训练完成 ---\")\n",
    "\n",
    "MODEL_SAVE_PATH = 'lstm_joke_generator.pth'\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "print(f\"模型已保存到: {MODEL_SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c914592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T05:23:53.898176Z",
     "iopub.status.busy": "2025-11-10T05:23:53.897836Z",
     "iopub.status.idle": "2025-11-10T05:23:54.514951Z",
     "shell.execute_reply": "2025-11-10T05:23:54.514112Z"
    },
    "papermill": {
     "duration": 0.621798,
     "end_time": "2025-11-10T05:23:54.516231",
     "exception": false,
     "start_time": "2025-11-10T05:23:53.894433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "模型加载成功！\n",
      "\n",
      "输入: 'If life gives you melons'\n",
      "生成: 'if life gives you melons you bees ever eat a job i tattooed on his <unk> network. tonight and it'\n",
      "\n",
      "输入: 'why did the chicken'\n",
      "生成: 'why did the chicken cross the road? it got them to have to ever knows it still hasn't got'\n",
      "\n",
      "--- 更多生成示例 ---\n",
      "输入: 'What do you call'\n",
      "生成: 'what do you call a kid on 14. teacher promoted to <unk> jared fogle in the'\n",
      "--------------------------------------------------\n",
      "输入: 'I went to the'\n",
      "生成: 'i went to the doctor away... for gas in her pocket and nine advice sign. voting'\n",
      "--------------------------------------------------\n",
      "输入: 'There was a'\n",
      "生成: 'there was a christian bale a woman to say it was dating my money for'\n",
      "--------------------------------------------------\n",
      "输入: 'My doctor told me'\n",
      "生成: 'my doctor told me i knew a mexican, apology to <unk> yay looks man &amp; a'\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "loaded_model = LSTMModel(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM).to(device)\n",
    "loaded_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"\\n模型加载成功！\")\n",
    "def generate_text(model, start_text, max_len=10):\n",
    "    model.eval()\n",
    "    words = start_text.lower().split()\n",
    "\n",
    "    hidden = model.init_hidden(1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(max_len):\n",
    "            input_seq = words[-4:]\n",
    "            input_ids = torch.tensor([[dataset.word2id.get(w, 0) for w in input_seq]]).to(device)\n",
    "            output, hidden = model(input_ids, hidden)\n",
    "\n",
    "            last_word_logits = output[0, -1, :]\n",
    "\n",
    "            p = torch.nn.functional.softmax(last_word_logits, dim=0).cpu().numpy()\n",
    "\n",
    "            word_index = np.random.choice(len(p), p=p)\n",
    "\n",
    "            words.append(dataset.id2word[word_index])\n",
    "            \n",
    "    return ' '.join(words)\n",
    "\n",
    "input_text = \"If life gives you melons\"\n",
    "generated_text = generate_text(loaded_model, input_text, max_len=15)\n",
    "\n",
    "print(f\"\\n输入: '{input_text}'\")\n",
    "print(f\"生成: '{generated_text}'\")\n",
    "\n",
    "input_text_2 = \"why did the chicken\"\n",
    "generated_text_2 = generate_text(loaded_model, input_text_2, max_len=15)\n",
    "print(f\"\\n输入: '{input_text_2}'\")\n",
    "print(f\"生成: '{generated_text_2}'\")\n",
    "\n",
    "test_inputs = [\n",
    "    \"What do you call\",\n",
    "    \"I went to the\",\n",
    "    \"There was a\",\n",
    "    \"My doctor told me\"\n",
    "]\n",
    "\n",
    "print(\"\\n--- 更多生成示例 ---\")\n",
    "for text in test_inputs:\n",
    "    generated = generate_text(loaded_model, text, max_len=12)\n",
    "    print(f\"输入: '{text}'\")\n",
    "    print(f\"生成: '{generated}'\")\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 781,
     "sourceId": 1457,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8852.482852,
   "end_time": "2025-11-10T05:23:57.069788",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-10T02:56:24.586936",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
